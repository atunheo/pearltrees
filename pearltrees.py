# streamlit_app.py
import streamlit as st
import requests
import re
import time
import pandas as pd
from io import BytesIO

st.set_page_config(page_title="Pearltrees Crawler", page_icon="üåø", layout="centered")

# --- API endpoints ---
TREE_SIBLING_API = "https://www.pearltrees.com/s/treeandpearlsapi/getPearlParentTreeAndSiblingPearls"
PRELOAD_API = "https://www.pearltrees.com/s/readerapi/preloadPearlReaderInfo"

# --- default headers to mimic a browser (helps tr√°nh l·ªói 500) ---
DEFAULT_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36"
    ),
    "Accept": "application/json, text/plain, */*",
    "Referer": "https://www.pearltrees.com/",
    "Origin": "https://www.pearltrees.com",
    "X-Requested-With": "XMLHttpRequest",
}

# ---------- helper functions ----------
def extract_pearl_id_from_url(url: str):
    """T√¨m pearlId trong URL d·∫°ng .../item123456"""
    m = re.search(r"item(\d+)", url)
    if m:
        return int(m.group(1))
    # th·ª≠ t√¨m query param pearlId=...
    m2 = re.search(r"pearlId=(\d+)", url)
    if m2:
        return int(m2.group(1))
    return None

def try_find_seed_pearl_from_username(username: str, timeout=10):
    """
    C·ªë g·∫Øng l·∫•y 1 pearlId kh·ªüi ƒë·∫ßu b·∫±ng c√°ch fetch trang user v√† qu√©t item\d+
    Tr·∫£ v·ªÅ list (c√≥ th·ªÉ r·ªóng) c√°c pearlId t√¨m ƒë∆∞·ª£c.
    """
    url = f"https://www.pearltrees.com/{username}"
    try:
        r = requests.get(url, headers=DEFAULT_HEADERS, timeout=timeout)
        if r.status_code != 200:
            return []
        html = r.text
        ids = set(map(int, re.findall(r"item(\d+)", html)))
        return sorted(ids)
    except Exception:
        return []

def preload_pearl_info(user_id: int, pearl_id: int, timeout=10):
    """G·ªçi preloadPearlReaderInfo ƒë·ªÉ l·∫•y chi ti·∫øt (c√≥ browserUrl, userId...)"""
    try:
        params = {"userId": user_id, "pearlId": pearl_id}
        r = requests.get(PRELOAD_API, params=params, headers=DEFAULT_HEADERS, timeout=timeout)
        if r.status_code != 200:
            return None
        return r.json()
    except Exception:
        return None

def get_pearl_detail_by_pearlid(pearl_id: int, timeout=10):
    """
    Th·ª≠ l·∫•y userId + browserUrl cho 1 pearlId.
    V√¨ preload c·∫ßn userId, ta th·ª≠ g·ªçi preload v·ªõi userId=0 (m·ªôt s·ªë tr∆∞·ªùng h·ª£p tr·∫£ userId),
    n·∫øu kh√¥ng, c·ªë g·∫Øng g·ªçi getPearlParentTreeAndSiblingPearls ƒë·ªÉ t√¨m d·ªØ li·ªáu k√®m userId.
    """
    # 1) Th·ª≠ preload v·ªõi userId=0 (nhi·ªÅu endpoint tr·∫£ d·ªØ li·ªáu c∆° b·∫£n b·∫•t ch·∫•p userId)
    info = preload_pearl_info(0, pearl_id, timeout=timeout)
    if info and isinstance(info, dict):
        # t√¨m browserUrl v√† userId (n·∫øu c√≥)
        browser_url = info.get("browserUrl") or info.get("pearl", {}).get("browserUrl")
        user_id = info.get("userId") or info.get("pearl", {}).get("ownerUserId")
        return {"pearlId": pearl_id, "browserUrl": browser_url, "userId": user_id, "raw": info}

    # 2) N·∫øu kh√¥ng c√≥, g·ªçi tree sibling API ƒë·ªÉ t√¨m object ch·ª©a id-> c√≥ th·ªÉ ch·ª©a h∆°n
    try:
        r = requests.get(TREE_SIBLING_API, params={"pearlId": pearl_id}, headers=DEFAULT_HEADERS, timeout=timeout)
        if r.status_code == 200:
            data = r.json()
            # t√¨m browserUrl ho·∫∑c id owner trong data
            # scan dict for browserUrl or userId
            browser_url = None
            user_id = None
            def find_fields(obj):
                nonlocal browser_url, user_id
                if isinstance(obj, dict):
                    if "browserUrl" in obj and not browser_url:
                        browser_url = obj.get("browserUrl")
                    if "userId" in obj and not user_id:
                        user_id = obj.get("userId")
                    for v in obj.values():
                        find_fields(v)
                elif isinstance(obj, list):
                    for it in obj:
                        find_fields(it)
            find_fields(data)
            return {"pearlId": pearl_id, "browserUrl": browser_url, "userId": user_id, "raw": data}
    except Exception:
        pass

    return {"pearlId": pearl_id, "browserUrl": None, "userId": None, "raw": None}

def get_related_pearl_ids(pearl_id: int, timeout=10):
    """G·ªçi getPearlParentTreeAndSiblingPearls ƒë·ªÉ l·∫•y c√°c pearl li√™n quan (child/sibling)"""
    try:
        r = requests.get(TREE_SIBLING_API, params={"pearlId": pearl_id}, headers=DEFAULT_HEADERS, timeout=timeout)
        if r.status_code != 200:
            return []
        data = r.json()
        ids = set()
        # duy·ªát data ƒë·ªÉ thu id
        def extract(obj):
            if isinstance(obj, dict):
                if "id" in obj and isinstance(obj["id"], int):
                    ids.add(obj["id"])
                for v in obj.values():
                    extract(v)
            elif isinstance(obj, list):
                for it in obj:
                    extract(it)
        extract(data)
        return list(ids)
    except Exception:
        return []

# ---------- crawling logic ----------
def crawl_from_seed(seed_pearl_id: int, max_items: int = 500, delay: float = 0.5):
    """
    Duy·ªát BFS t·ª´ seed_pearl_id, thu t·∫•t c·∫£ pearlId v√† browserUrl (khi c√≥).
    max_items gi·ªõi h·∫°n t·ªïng s·ªë nodes ƒë·ªÉ tr√°nh qu√° t·∫£i.
    """
    visited = set()
    to_visit = [seed_pearl_id]
    results = []
    steps = 0

    progress = st.progress(0)
    status_text = st.empty()

    while to_visit and len(visited) < max_items:
        current = to_visit.pop(0)
        if current in visited:
            continue
        visited.add(current)

        status_text.info(f"ƒêang x·ª≠ l√Ω pearlId: {current}  ‚Äî ƒë√£ thu: {len(results)} / gi·ªõi h·∫°n {max_items}")
        info = get_pearl_detail_by_pearlid(current)
        browser_url = info.get("browserUrl") if info else None
        user_id = info.get("userId") if info else None

        results.append({"pearlId": current, "browserUrl": browser_url, "userId": user_id})
        # l·∫•y related ids
        related = get_related_pearl_ids(current)
        for r in related:
            if r not in visited and r not in to_visit:
                to_visit.append(r)

        steps += 1
        progress.progress(min(steps / max_items, 1.0))
        time.sleep(delay)

    status_text.success(f"Ho√†n t·∫•t: thu ƒë∆∞·ª£c {len(results)} item(s).")
    return results

# ---------- Streamlit UI ----------
st.title("üåø Pearltrees ‚Äî L·∫•y Pearl ID & URLs")
st.markdown(
    "B·∫°n c√≥ th·ªÉ nh·∫≠p **T√™n t√†i kho·∫£n** ho·∫∑c **d√°n tr·ª±c ti·∫øp 1 URL item** (v√≠ d·ª•: "
    "`https://www.pearltrees.com/heiliaounu/item751860259`).\n\n"
    "- N·∫øu nh·∫≠p username, app s·∫Ω c·ªë g·∫Øng t√¨m 1 seed `pearlId` t·ª´ trang public.\n"
    "- Sau ƒë√≥ app duy·ªát ƒë·ªá quy (BFS) qua API `getPearlParentTreeAndSiblingPearls` ƒë·ªÉ thu to√†n b·ªô `pearlId` v√† `browserUrl`."
)

col1, col2 = st.columns(2)
with col1:
    user_input = st.text_input("T√™n t√†i kho·∫£n (v√≠ d·ª•: heiliaounu)", value="")
with col2:
    url_input = st.text_input("Ho·∫∑c d√°n 1 URL item (v√≠ d·ª• ch·ª©a 'item123...')", value="")

max_items = st.number_input("Gi·ªõi h·∫°n s·ªë items t·ªëi ƒëa (ƒë·ªÉ tr√°nh qu√° t·∫£i)", min_value=10, max_value=5000, value=600, step=10)
delay = st.slider("Delay gi·ªØa c√°c request (gi√¢y)", min_value=0.1, max_value=3.0, value=0.5, step=0.1)

if st.button("üöÄ B·∫Øt ƒë·∫ßu thu th·∫≠p"):
    seed_ids = []
    seed_pearl = None

    # 1) n·∫øu user d√°n URL item th√¨ ∆∞u ti√™n l·∫•y pearlId t·ª´ ƒë√≥
    if url_input and "pearltrees.com" in url_input:
        pid = extract_pearl_id_from_url(url_input)
        if pid:
            seed_ids = [pid]
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y 'item<ID>' trong URL. Vui l√≤ng d√°n ƒë√∫ng URL item.")
    # 2) n·∫øu ch·ªâ c√≥ username -> c·ªë g·∫Øng qu√©t HTML ƒë·ªÉ t√¨m item ids
    elif user_input:
        found = try_find_seed_pearl_from_username(user_input)
        if found:
            seed_ids = found  # d√πng c√°c ids t√¨m ƒë∆∞·ª£c (th·ª© t·ª± tƒÉng d·∫ßn)
        else:
            st.warning("Kh√¥ng t√¨m th·∫•y pearlId trong trang user c√¥ng khai. Vui l√≤ng d√°n 1 URL item c·ª• th·ªÉ.")
    else:
        st.warning("Vui l√≤ng nh·∫≠p username ho·∫∑c d√°n 1 URL item.")
    
    # N·∫øu c√≥ seed, ti·∫øn h√†nh crawl (∆∞u ti√™n id ƒë·∫ßu ti√™n)
    if seed_ids:
        seed = seed_ids[0]
        st.info(f"S·ª≠ d·ª•ng seed pearlId = {seed}  (t·ªïng seed t√¨m th·∫•y: {len(seed_ids)})")
        with st.spinner("‚è≥ ƒêang crawl..."):
            results = crawl_from_seed(seed, max_items=int(max_items), delay=float(delay))
            if results:
                df = pd.DataFrame(results)
                st.success(f"‚úÖ Thu th·∫≠p xong ‚Äî t·ªïng {len(df)} items.")
                st.dataframe(df)

                # Xu·∫•t Excel (BytesIO)
                buffer = BytesIO()
                df.to_excel(buffer, index=False, engine="openpyxl")
                buffer.seek(0)
                st.download_button(
                    "üì• T·∫£i file Excel",
                    data=buffer,
                    file_name="pearltrees_links.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.info("Kh√¥ng thu th·∫≠p ƒë∆∞·ª£c item n√†o. C√≥ th·ªÉ t√†i kho·∫£n private ho·∫∑c API b·ªã h·∫°n ch·∫ø.")
